name: Update Sports Data

on:
  # Run every 2 hours
  schedule:
    - cron: "0 */2 * * *"

  # Allow manual trigger with runner selection
  workflow_dispatch:
    inputs:
      runner:
        description: 'Runner type'
        required: false
        default: 'self-hosted'
        type: choice
        options:
          - self-hosted
          - ubuntu-latest

  # Run on pushes to main branch (for testing)
  push:
    branches: [main]
    paths:
      - ".github/workflows/update-sports-data.yml"
      - "scripts/**"

concurrency:
  group: sportsync-commits
  cancel-in-progress: false

jobs:
  update-data:
    runs-on: ${{ inputs.runner == 'ubuntu-latest' && 'ubuntu-latest' || fromJSON('["self-hosted","linux","ARM64"]') }}
    permissions:
      contents: write
      issues: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install dependencies
        run: |
          npm install node-fetch@2.7.0
          npm install

      - name: Create data directory
        run: |
          mkdir -p docs/data

      - name: Fetch All Sports Data
        run: |
          npm run update:data || echo "Sports data fetch failed, continuing with available data"

      - name: Merge data + Fetch standings + Fetch RSS (parallel)
        run: |
          node scripts/merge-open-data.js &
          PID_MERGE=$!
          node scripts/fetch-standings.js &
          PID_STANDINGS=$!
          node scripts/fetch-rss.js &
          PID_RSS=$!

          FAIL=0
          wait $PID_MERGE || { echo "Merge step failed"; FAIL=1; }
          wait $PID_STANDINGS || { echo "Standings fetch failed"; FAIL=1; }
          wait $PID_RSS || { echo "RSS fetch failed"; FAIL=1; }

          if [ $FAIL -ne 0 ]; then
            echo "One or more parallel steps failed (non-fatal)"
          fi

      - name: Fetch recent results
        run: |
          node scripts/fetch-results.js || echo "Results fetch failed (non-fatal)"

      - name: Sync configs
        run: |
          node scripts/sync-configs.js || echo "Config sync failed (non-fatal)"

      - name: Snapshot usage (before AI)
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: node scripts/track-usage.js snapshot || echo "Usage snapshot failed (non-fatal)"

      - name: Discover events
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          node scripts/discover-events.js || echo "Event discovery failed (non-fatal)"

      - name: Generate aggregated events file
        run: |
          npm run build:events || echo "Aggregation failed"

      - name: Enrich events with AI
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          npm run enrich || echo "AI enrichment failed, using raw data"

      - name: Generate featured content
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          npm run generate:featured || echo "Featured generation failed, using fallback"

      - name: Generate multi-day briefings
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          node scripts/generate-multi-day.js --backfill 5 || echo "Multi-day briefings failed (non-fatal)"

      - name: Build day snapshots
        run: |
          node scripts/build-day-snapshots.js || echo "Day snapshot build failed (non-fatal)"

      - name: Report usage (after AI)
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: node scripts/track-usage.js report pipeline || echo "Usage report failed (non-fatal)"

      - name: Validate unified events (future-only)
        run: |
          npm run validate:data

      - name: Pipeline health check
        run: |
          node scripts/pipeline-health.js || true

      - name: Quality regression + Coverage gaps + Calendar (parallel)
        run: |
          node scripts/check-quality-regression.js &
          PID_QUALITY=$!
          node scripts/detect-coverage-gaps.js &
          PID_GAPS=$!
          npm run build:calendar &
          PID_CAL=$!

          wait $PID_QUALITY || echo "Quality regression check failed"
          wait $PID_GAPS || echo "Coverage gap detection failed"
          wait $PID_CAL || echo "Calendar build failed"

      - name: AI sanity check
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          node scripts/ai-sanity-check.js || echo "Sanity check failed (non-fatal)"

      - name: Update meta timestamp
        run: |
          echo '{
            "lastUpdate": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'",
            "nextUpdate": "'$(date -u -d "+2 hours 10 minutes" +"%Y-%m-%dT%H:%M:%SZ")'",
            "timezone": "Europe/Oslo",
            "openSources": true
          }' > docs/data/meta.json

      - name: Pre-commit gate
        id: gate
        run: |
          node scripts/pre-commit-gate.js && echo "gate=pass" >> $GITHUB_OUTPUT || echo "gate=fail" >> $GITHUB_OUTPUT

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          if [ "${{ steps.gate.outputs.gate }}" = "fail" ]; then
            echo "Gate failed â€” committing health/monitoring files only"
            git add docs/data/health-report.json docs/data/coverage-gaps.json docs/data/ai-quality.json 2>/dev/null || true
          else
            git add docs/data/
            git add docs/data/days/ 2>/dev/null || true
            git add scripts/config/ 2>/dev/null || true
          fi
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ðŸ”„ Update sports data with real API sources - $(date -u +"%Y-%m-%d %H:%M UTC")"
            for i in 1 2 3; do
              git push && break
              echo "Push attempt $i failed, rebasing..."
              git pull --rebase origin main || true
              sleep 5
            done
          fi

      - name: Trigger preview deployment
        if: success()
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.repos.createDispatchEvent({
              owner: context.repo.owner,
              repo: context.repo.repo,
              event_type: 'preview-deploy'
            });

      - name: Summary
        run: |
          echo "## ðŸ“Š Sports Data Update Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u +"%Y-%m-%d %H:%M UTC")" >> $GITHUB_STEP_SUMMARY
          echo "- **Football**: $(jq -r '.tournaments | length' docs/data/football.json 2>/dev/null || echo 0) tournaments" >> $GITHUB_STEP_SUMMARY
          echo "- **Golf**: $(jq -r '.tournaments | length' docs/data/golf.json 2>/dev/null || echo 0) tournaments" >> $GITHUB_STEP_SUMMARY
          echo "- **Tennis**: $(jq -r '.tournaments | length' docs/data/tennis.json 2>/dev/null || echo 0) tournaments" >> $GITHUB_STEP_SUMMARY
          echo "- **F1**: $(jq -r '.tournaments[0].events | length' docs/data/f1.json 2>/dev/null || echo 0) races" >> $GITHUB_STEP_SUMMARY
          echo "- **Chess**: $(jq -r '.tournaments | length' docs/data/chess.json 2>/dev/null || echo 0) tournaments" >> $GITHUB_STEP_SUMMARY
          echo "- **Esports**: $(jq -r '.tournaments | length' docs/data/esports.json 2>/dev/null || echo 0) tournaments" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f docs/data/events.json ]; then
            TOTAL=$(jq -r 'length' docs/data/events.json 2>/dev/null || echo 0)
            echo "- **Total Events**: $TOTAL" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f docs/data/events.json ]; then
            ENRICHED=$(jq -r '[.[] | select(.importance != null)] | length' docs/data/events.json 2>/dev/null || echo 0)
            echo "- **AI Enriched**: $ENRICHED/$TOTAL events" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f docs/data/events.ics ]; then
            SIZE=$(wc -c < docs/data/events.ics | tr -d ' ')
            echo "- **ICS Calendar**: ${SIZE} bytes" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f docs/data/health-report.json ]; then
            STATUS=$(jq -r '.status' docs/data/health-report.json 2>/dev/null || echo "unknown")
            ISSUES=$(jq -r '.issues | length' docs/data/health-report.json 2>/dev/null || echo 0)
            echo "- **Pipeline Health**: $STATUS ($ISSUES issues)" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f docs/data/coverage-gaps.json ]; then
            GAPS=$(jq -r '.summary.totalGapsDetected' docs/data/coverage-gaps.json 2>/dev/null || echo 0)
            echo "- **Coverage Gaps**: $GAPS detected" >> $GITHUB_STEP_SUMMARY
          fi
          GATE="${{ steps.gate.outputs.gate }}"
          if [ "$GATE" = "fail" ]; then
            echo "âš ï¸ Pre-commit gate FAILED â€” only monitoring files committed" >> $GITHUB_STEP_SUMMARY
          fi
          echo "- **Runner**: ${{ runner.name }} (${{ runner.os }})" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Dashboard updated with current week real data only!" >> $GITHUB_STEP_SUMMARY

      - name: Cleanup (self-hosted)
        if: always() && !contains(runner.name, 'GitHub Actions')
        run: rm -rf node_modules 2>/dev/null || true
